{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69da58b-160e-42fc-8701-2b4cb7602155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 40000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_data = []\n",
    "\n",
    "data_point_num = 10000\n",
    "\n",
    "# User Intent 1: Requesting cab availability\n",
    "cab_availability_data = []\n",
    "\n",
    "availability_questions = [\n",
    "    \"Is there a cab that can take me to {}?\",\n",
    "    \"Are there any cabs going to {} soon?\",\n",
    "    \"Can I get a ride to {}?\",\n",
    "    \"How soon can I get a cab to {}?\",\n",
    "    \"Any available cabs for {} now?\",\n",
    "    \"What's the waiting time for a cab to {}?\"\n",
    "]\n",
    "\n",
    "destinations = [\n",
    "    \"Central Park\",\n",
    "    \"Times Square\",\n",
    "    \"Madison Square Garden\",\n",
    "    \"Empire State Building\",\n",
    "    \"Museum of Modern Art\",\n",
    "    \"Statue of Liberty\",\n",
    "    \"JFK Airport\",\n",
    "    \"LaGuardia Airport\",\n",
    "    \"Brooklyn Bridge\",\n",
    "    \"Wall Street\"\n",
    "]\n",
    "\n",
    "for _ in range(data_point_num):\n",
    "    destination = random.choice(destinations)\n",
    "    user_query = random.choice(availability_questions).format(destination)\n",
    "    \n",
    "    # Introduce variety in response time details\n",
    "    minutes = random.randint(1, 15)\n",
    "    rough_times = [\"a few\", \"several\", \"a couple of\"]\n",
    "    approx_time = random.choice(rough_times)\n",
    "    \n",
    "    positive_responses = [\n",
    "        f\"Yes, we have a cab {minutes} minutes away for {destination}.\",\n",
    "        f\"A cab is on its way and should be there in about {minutes} minutes for {destination}.\",\n",
    "        f\"There's a cab just around the corner! It'll take approximately {minutes} minutes to reach you for your trip to {destination}.\",\n",
    "        f\"You're in luck! A cab is {approx_time} minutes away from {destination}.\"\n",
    "    ]\n",
    "    \n",
    "    negative_responses = [\n",
    "        f\"I'm sorry, there are currently no cabs available for {destination}.\",\n",
    "        f\"It seems all our cabs are booked at the moment for trips to {destination}. Can you wait a bit?\",\n",
    "        f\"We're experiencing high demand right now for {destination}. It might take longer than usual.\"\n",
    "    ]\n",
    "    \n",
    "    # Decide if a positive or negative response should be given (80-20 split for this example)\n",
    "    response_type_choice = random.choices(\n",
    "        [\"positive\", \"negative\"], \n",
    "        weights=[0.8, 0.2], \n",
    "        k=1\n",
    "    )[0]\n",
    "    \n",
    "    if response_type_choice == \"positive\":\n",
    "        response = random.choice(positive_responses)\n",
    "    else:\n",
    "        response = random.choice(negative_responses)\n",
    "    \n",
    "    cab_availability_data.append([user_query, response])\n",
    "\n",
    "\n",
    "# User Intent 2: Inquiring about fare estimates\n",
    "fare_estimate_data = []\n",
    "\n",
    "fare_questions = [\n",
    "    \"What would be the fare to {}?\",\n",
    "    \"How much would it cost to go to {}?\",\n",
    "    \"Can you give me a price estimate for a trip to {}?\",\n",
    "    \"What's the charge for a ride to {}?\",\n",
    "    \"What's the expected fare for {}?\",\n",
    "    \"Give me a ballpark figure for a ride to {}.\"\n",
    "]\n",
    "\n",
    "for _ in range(data_point_num):\n",
    "    destination = random.choice(destinations)\n",
    "    user_query = random.choice(fare_questions).format(destination)\n",
    "    \n",
    "    fare_low = random.randint(10, 40)\n",
    "    fare_high = fare_low + random.randint(5, 15)  # Upper estimate range\n",
    "    \n",
    "    standard_responses = [\n",
    "        f\"The estimated fare to {destination} is approximately ${fare_low:.2f}.\",\n",
    "        f\"You'd be looking at around ${fare_low:.2f} to get to {destination}.\",\n",
    "        f\"Expect the fare to {destination} to be close to ${fare_low:.2f}.\"\n",
    "    ]\n",
    "    \n",
    "    range_responses = [\n",
    "        f\"The estimated fare to {destination} is between ${fare_low:.2f} and ${fare_high:.2f} depending on traffic.\",\n",
    "        f\"A trip to {destination} could cost anywhere from ${fare_low:.2f} to ${fare_high:.2f}, based on the route taken.\",\n",
    "        f\"Based on current demand, the fare to {destination} is roughly ${fare_low:.2f} to ${fare_high:.2f}.\"\n",
    "    ]\n",
    "    \n",
    "    uncertain_responses = [\n",
    "        f\"The fare to {destination} can vary, but it's usually around ${fare_low:.2f}.\",\n",
    "        f\"It's hard to pinpoint an exact fare now, but I'd estimate near ${fare_low:.2f} for {destination}.\",\n",
    "        f\"With the current traffic, it might be close to ${fare_low:.2f} to reach {destination}.\"\n",
    "    ]\n",
    "    \n",
    "    # Decide the type of response (even distribution for this example, can be adjusted)\n",
    "    response_type_choice = random.choices(\n",
    "        [\"standard\", \"range\", \"uncertain\"], \n",
    "        weights=[0.5, 0.3, 0.2], \n",
    "        k=1\n",
    "    )[0]\n",
    "    \n",
    "    if response_type_choice == \"standard\":\n",
    "        response = random.choice(standard_responses)\n",
    "    elif response_type_choice == \"range\":\n",
    "        response = random.choice(range_responses)\n",
    "    else:\n",
    "        response = random.choice(uncertain_responses)\n",
    "    \n",
    "    fare_estimate_data.append([user_query, response])\n",
    "\n",
    "\n",
    "# User Intent 3: Frequently Asked Questions\n",
    "faq_data = []\n",
    "\n",
    "faq_dictionary = {\n",
    "    \"What hours do you operate?\": [\n",
    "        \"We're available 24/7.\", \n",
    "        \"Our cabs operate around the clock, 24/7.\", \n",
    "        \"Anytime! We're always operational.\"\n",
    "    ],\n",
    "    \"Tell me your operating times.\": [\n",
    "        \"Our services run 24/7 for your convenience.\",\n",
    "        \"You can book with us any time of the day, 365 days a year.\",\n",
    "        \"We don't close! Available every hour, every day.\"\n",
    "    ],\n",
    "    \"When can I book a cab?\": [\n",
    "        \"Feel free to book anytime, we're open 24/7.\",\n",
    "        \"We're at your service around the clock. Book whenever you need.\",\n",
    "        \"Day or night, we're here for you!\"\n",
    "    ],\n",
    "    \"Can I pay using my credit card?\": [\n",
    "        \"Yes, we accept all major credit cards and online payment methods.\",\n",
    "        \"Absolutely! All major cards are supported.\",\n",
    "        \"Definitely! Pay the way you prefer, including credit cards.\"\n",
    "    ],\n",
    "    \"Do you guys accept cards?\": [\n",
    "        \"Yes, we take all major credit and debit cards.\",\n",
    "        \"Cards? Absolutely! We support most of them.\",\n",
    "        \"Of course! Whether it's Visa, Mastercard, or others, we've got you covered.\"\n",
    "    ],\n",
    "    \"What's the process to cancel my booking?\": [\n",
    "        \"It's simple. Use our app or call our customer service. Remember, cancel at least an hour ahead.\",\n",
    "        \"Go to our app, find your booking, and hit 'Cancel'. Or, give us a ring!\",\n",
    "        \"Through the app is the quickest. If not, our helpline is always available.\"\n",
    "    ],\n",
    "    \"How do I go about canceling a ride?\": [\n",
    "        \"Open our app, find your trip, and tap on 'Cancel'. Alternatively, you can always call us.\",\n",
    "        \"Cancellations are easy! Just ensure you do it in advance to avoid charges.\",\n",
    "        \"Either through the app or by calling our support. We recommend doing it an hour before your trip.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "faq_questions = list(faq_dictionary.keys())\n",
    "\n",
    "for _ in range(data_point_num):\n",
    "    user_query = random.choice(faq_questions)\n",
    "    response = random.choice(faq_dictionary[user_query])\n",
    "    faq_data.append([user_query, response])\n",
    "\n",
    "\n",
    "# User Intent 4: Personalized cab recommendations\n",
    "personalized_recommendations_data = []\n",
    "\n",
    "recommendations_dictionary = {\n",
    "    \"What cab suits my previous bookings?\": [\n",
    "        \"Considering your past preferences, we'd suggest our executive sedan.\",\n",
    "        \"From what you've chosen before, our standard sedan might be your go-to.\",\n",
    "        \"How about our premium SUV? It aligns with your previous bookings.\"\n",
    "    ],\n",
    "    \"Can you suggest a comfy ride?\": [\n",
    "        \"Our plush sedan is known for its comfort. Give it a try!\",\n",
    "        \"An executive SUV from us guarantees a smooth ride.\",\n",
    "        \"For a relaxing journey, nothing beats our premium sedans.\"\n",
    "    ],\n",
    "    \"I'm looking for eco-friendly options. Any recommendations?\": [\n",
    "        \"Certainly! Our electric vehicle fleet is top-notch and eco-friendly.\",\n",
    "        \"Our hybrid cabs are a perfect blend of efficiency and eco-friendliness.\",\n",
    "        \"Go green with our latest electric sedan!\"\n",
    "    ],\n",
    "    \"I want a luxurious experience. What do you suggest?\": [\n",
    "        \"Nothing speaks luxury like our exclusive luxury lineup.\",\n",
    "        \"Why not try our luxury SUV? It's designed for superior experiences.\",\n",
    "        \"Our premium class offers unparalleled luxury and comfort.\"\n",
    "    ],\n",
    "    \"I need a cheap option. What do you have?\": [\n",
    "        \"Our basic hatchback is not only reliable but also budget-friendly.\",\n",
    "        \"For an economical trip, our standard sedan does wonders.\",\n",
    "        \"Our compact cars are designed to be light on your pocket.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "recommendation_questions = list(recommendations_dictionary.keys())\n",
    "\n",
    "for _ in range(data_point_num):\n",
    "    user_query = random.choice(recommendation_questions)\n",
    "    response = random.choice(recommendations_dictionary[user_query])\n",
    "    personalized_recommendations_data.append([user_query, response])\n",
    "\n",
    "# User Intent 5: Specifying cab preferences\n",
    "cab_preferences_data = []\n",
    "\n",
    "preferences_dictionary = {\n",
    "    \"Do you have cabs with a child seat?\": [\n",
    "        \"Certainly! We'll send a cab with a child seat for you.\",\n",
    "        \"Of course, we can arrange cabs equipped with child seats.\",\n",
    "        \"No worries, let's arrange a cab with a child seat for you.\"\n",
    "    ],\n",
    "    \"I need a ride that's wheelchair accessible.\": [\n",
    "        \"Absolutely, we prioritize accessibility. We'll arrange a wheelchair-accessible cab.\",\n",
    "        \"Yes, we do have cabs that are wheelchair accessible. We'll send one right away.\",\n",
    "        \"For sure, let us arrange a wheelchair-accessible cab for you.\"\n",
    "    ],\n",
    "    \"Got any cabs with extra legroom?\": [\n",
    "        \"Sure thing! Our SUVs have that extra space you're looking for.\",\n",
    "        \"Absolutely, our executive sedans offer ample legroom.\",\n",
    "        \"You'll love our spacious vehicles designed especially for that extra legroom.\"\n",
    "    ],\n",
    "    \"Can I get a cab with a luggage rack?\": [\n",
    "        \"Yes, let's get you a cab equipped with a luggage rack.\",\n",
    "        \"Of course, we'll arrange a cab with a luggage rack for you.\",\n",
    "        \"Absolutely, we have cabs ready with luggage racks.\"\n",
    "    ],\n",
    "    \"Do you have cabs with tinted windows?\": [\n",
    "        \"Certainly, for those who prefer added privacy, we have cabs with tinted windows.\",\n",
    "        \"Yes, let us arrange a cab with tinted windows for you.\",\n",
    "        \"For sure, we have a fleet with tinted windows. One's on its way.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "non_availability_responses = [\n",
    "    \"I'm sorry, we don't have that feature available at the moment.\",\n",
    "    \"Apologies, we're currently out of cabs with that specific feature.\",\n",
    "    \"Regrettably, we can't accommodate that request right now.\"\n",
    "]\n",
    "\n",
    "preference_questions = list(preferences_dictionary.keys())\n",
    "\n",
    "probability_feature_available = 0.8\n",
    "\n",
    "for _ in range(data_point_num):\n",
    "    user_query = random.choice(preference_questions)\n",
    "    \n",
    "    if random.random() < probability_feature_available:\n",
    "        response = random.choice(preferences_dictionary[user_query])\n",
    "    else:\n",
    "        response = random.choice(non_availability_responses)\n",
    "    \n",
    "    cab_preferences_data.append([user_query, response])\n",
    "\"\"\"\n",
    "# Morning Noonj Evening\n",
    "times_of_day = [\"morning\", \"noon\", \"evening\"]\n",
    "\n",
    "morning_faq_responses = [\n",
    "    \"Our morning shift starts at 6 am.\",\n",
    "    \"Cabs are readily available in the mornings!\",\n",
    "    \"Morning fares are generally consistent and don't see much fluctuation.\",\n",
    "    \"Our drivers in the morning shift are refreshed and ready to ensure a smooth ride.\",\n",
    "    \"You can expect minimal traffic during early morning rides.\"\n",
    "]\n",
    "\n",
    "noon_faq_responses = [\n",
    "    \"During noon, there might be peak charges due to high demand.\",\n",
    "    \"Noon rides, especially around lunchtime, can experience a bit of traffic.\",\n",
    "    \"Our cabs are equipped with air conditioning to ensure a comfortable ride during the hot noon hours.\",\n",
    "    \"If you're booking at noon, please allow a slightly longer waiting time due to demand.\",\n",
    "    \"Many drivers take their breaks during noon, but we always have a fleet ready for service.\"\n",
    "]\n",
    "\n",
    "evening_faq_responses = [\n",
    "    \"Night charges start from 8 pm onwards.\",\n",
    "    \"Evening hours, especially rush hour, might see some delays due to traffic.\",\n",
    "    \"For late-night rides, we recommend pre-booking to ensure availability.\",\n",
    "    \"Our drivers during the evening shift are experienced with nighttime driving.\",\n",
    "    \"We prioritize safety; our evening and night cabs are all equipped with GPS tracking.\"\n",
    "]\n",
    "\n",
    "\n",
    "faq_data = []\n",
    "for _ in range(data_point_num):\n",
    "    index = random.randrange(len(faq_questions_templates))\n",
    "    user_query = faq_questions_templates[index]\n",
    "    time_slot = random.choice(times_of_day)\n",
    "    \n",
    "    if time_slot == \"morning\":\n",
    "        response = random.choice(morning_faq_responses)\n",
    "    elif time_slot == \"noon\":\n",
    "        response = random.choice(noon_faq_responses)\n",
    "    else:  # evening\n",
    "        response = random.choice(evening_faq_responses)\n",
    "    \n",
    "    faq_data.append([user_query, response])\n",
    "\"\"\"\n",
    "\n",
    "# Frequently Asked Questions with Time-specific Responses\n",
    "faq_data = []\n",
    "faq_questions_templates = [\n",
    "    \"What hours do you operate?\",\n",
    "    \"Tell me your operating times.\",\n",
    "    \"When can I book a cab?\",\n",
    "    \"Can I pay using my credit card?\",\n",
    "    \"Do you guys accept cards?\",\n",
    "    \"What's the process to cancel my booking?\",\n",
    "    \"How do I go about canceling a ride?\"\n",
    "]\n",
    "\n",
    "times_of_day = [\"morning\", \"noon\", \"evening\"]\n",
    "\n",
    "morning_faq_responses = [\n",
    "    \"Our morning shift starts at 6 am.\",\n",
    "    \"Cabs are readily available in the mornings!\",\n",
    "    \"Morning fares are generally consistent and don't see much fluctuation.\",\n",
    "    \"Our drivers in the morning shift are refreshed and ready to ensure a smooth ride.\",\n",
    "    \"You can expect minimal traffic during early morning rides.\"\n",
    "]\n",
    "\n",
    "noon_faq_responses = [\n",
    "    \"During noon, there might be peak charges due to high demand.\",\n",
    "    \"Noon rides, especially around lunchtime, can experience a bit of traffic.\",\n",
    "    \"Our cabs are equipped with air conditioning to ensure a comfortable ride during the hot noon hours.\",\n",
    "    \"If you're booking at noon, please allow a slightly longer waiting time due to demand.\",\n",
    "    \"Many drivers take their breaks during noon, but we always have a fleet ready for service.\"\n",
    "]\n",
    "\n",
    "evening_faq_responses = [\n",
    "    \"Night charges start from 8 pm onwards.\",\n",
    "    \"Evening hours, especially rush hour, might see some delays due to traffic.\",\n",
    "    \"For late-night rides, we recommend pre-booking to ensure availability.\",\n",
    "    \"Our drivers during the evening shift are experienced with nighttime driving.\",\n",
    "    \"We prioritize safety; our evening and night cabs are all equipped with GPS tracking.\"\n",
    "]\n",
    "\n",
    "for _ in range(data_point_num):\n",
    "    index = random.randrange(len(faq_questions_templates))\n",
    "    user_query = faq_questions_templates[index]\n",
    "    time_slot = random.choice(times_of_day)\n",
    "    \n",
    "    if time_slot == \"morning\":\n",
    "        response = random.choice(morning_faq_responses)\n",
    "    elif time_slot == \"noon\":\n",
    "        response = random.choice(noon_faq_responses)\n",
    "    else:  # evening\n",
    "        response = random.choice(evening_faq_responses)\n",
    "    \n",
    "    faq_data.append([user_query, response])\n",
    "\n",
    "\n",
    "\n",
    "# Combining datasets\n",
    "datasets = [cab_availability_data, fare_estimate_data, faq_data, personalized_recommendations_data, cab_preferences_data]\n",
    "\n",
    "for dataset in datasets:\n",
    "    train_data += dataset\n",
    "\n",
    "# Shuffle the train_data to mix the different user intents\n",
    "random.shuffle(train_data)\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Sample train_data for the example\n",
    "train_data\n",
    "\n",
    "# Split data into separate questions and answers lists\n",
    "questions, answers = zip(*train_data)\n",
    "\n",
    "# Convert to Dataset\n",
    "full_dataset = Dataset.from_dict({\n",
    "    \"question\": list(questions),\n",
    "    \"answer\": list(answers)\n",
    "})\n",
    "\n",
    "# Splitting the dataset into train and validation sets in 4 to 1 ratio\n",
    "train_size = 0.8  # 80% for training\n",
    "split_datasets = full_dataset.train_test_split(test_size=1-train_size)\n",
    "\n",
    "# Creating DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split_datasets[\"train\"],\n",
    "    \"validation\": split_datasets[\"test\"]\n",
    "})\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c3e6b64-6a99-46cd-b342-7fad8d8f0f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the questions and answers\n",
    "    output = tokenizer(examples['question'], examples['answer'], truncation=True, padding='max_length', max_length=128)\n",
    "    # For GPT-2, the labels are the same as the input_ids\n",
    "    output[\"labels\"] = output[\"input_ids\"].copy()\n",
    "    return output\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "150d905e-0ac3-4c00-8442-04f6d55c0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "\n",
    "# Load the GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714c2012-b476-496d-8cea-ea497ec4ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # <-- This is the line you need to add.\n",
    "    per_device_train_batch_size=16,  # adjust based on your GPU memory\n",
    "    per_device_eval_batch_size=16,   # adjust based on your GPU memory\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90eead1-02c5-49a5-bb81-6f08b3a3c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42a56ab-9aa9-4e3d-a9e6-190f17d7b15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 12:07:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.051062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.051062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.05986613878011703, metrics={'train_runtime': 43674.2333, 'train_samples_per_second': 0.916, 'train_steps_per_second': 0.029, 'total_flos': 2612920320000000.0, 'train_loss': 0.05986613878011703, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49598f29-40b6-42f3-8d6b-dbfc9a48f554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990e306c-bdf0-4ff7-8a96-ded8eb68b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ccb232-38f7-4f08-b30e-851e2a87b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './my_finetuned_gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a38952a4-f91f-40b7-b5e4-0395e0a831a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=1.0, top_k=50):\n",
    "    # Encode the input prompt to tensor\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    \n",
    "    # Decode only the newly generated tokens (excluding the input prompt)\n",
    "    generated_tokens = output[0][input_ids.shape[1]:] \n",
    "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd61c1f9-1741-4aad-9f69-25346ba8875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you have a cab to Turkey?\n",
      "Yes, let us arrange a cab for you.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Do you have a cab to Turkey?\"\n",
    "result = generate_text(prompt)\n",
    "print(prompt)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
